{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennxf/anaconda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from keras import metrics\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df3.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = df.tags_id\n",
    "texts = df.keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]]\n",
      "(7893,) (7893, 30)\n"
     ]
    }
   ],
   "source": [
    "num_max = 30\n",
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags)\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)\n",
    "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
    "print(tags[:5])\n",
    "print(mat_texts[:5])\n",
    "print(tags.shape,mat_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 512)               15872     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 147,457\n",
      "Trainable params: 147,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "compile done\n",
      "Train on 6314 samples, validate on 1579 samples\n",
      "Epoch 1/10\n",
      "6314/6314 [==============================] - 1s 196us/step - loss: -174.3647 - acc: 0.0706 - binary_accuracy: 0.0706 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 2/10\n",
      "6314/6314 [==============================] - 1s 85us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 3/10\n",
      "6314/6314 [==============================] - 1s 84us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 4/10\n",
      "6314/6314 [==============================] - 1s 83us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 5/10\n",
      "6314/6314 [==============================] - 1s 86us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 6/10\n",
      "6314/6314 [==============================] - 1s 85us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 7/10\n",
      "6314/6314 [==============================] - 1s 84us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 8/10\n",
      "6314/6314 [==============================] - 1s 84us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 9/10\n",
      "6314/6314 [==============================] - 1s 83us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 10/10\n",
      "6314/6314 [==============================] - 1s 85us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n"
     ]
    }
   ],
   "source": [
    "# try a simple model first\n",
    "\n",
    "def get_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(num_max,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',metrics.binary_accuracy])\n",
    "    print('compile done')\n",
    "    return model\n",
    "\n",
    "def check_model(model,x,y):\n",
    "    model.fit(x,y,batch_size=32,epochs=10,verbose=1,validation_split=0.2)\n",
    "\n",
    "m = get_simple_model()\n",
    "check_model(m,mat_texts,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "(7893, 50)\n"
     ]
    }
   ],
   "source": [
    "max_len = 50\n",
    "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
    "print(cnn_texts_seq[0])\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "print(cnn_texts_mat[0])\n",
    "print(cnn_texts_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 50, 20)            20000     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 50, 20)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 48, 64)            3904      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,801\n",
      "Trainable params: 40,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6314 samples, validate on 1579 samples\n",
      "Epoch 1/10\n",
      "6314/6314 [==============================] - 2s 264us/step - loss: -159.3992 - acc: 0.0702 - binary_accuracy: 0.0702 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 2/10\n",
      "6314/6314 [==============================] - 1s 140us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 3/10\n",
      "6314/6314 [==============================] - 1s 136us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 4/10\n",
      "6314/6314 [==============================] - 1s 139us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 5/10\n",
      "6314/6314 [==============================] - 1s 139us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 6/10\n",
      "6314/6314 [==============================] - 1s 137us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 7/10\n",
      "6314/6314 [==============================] - 1s 137us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 8/10\n",
      "6314/6314 [==============================] - 1s 139us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 9/10\n",
      "6314/6314 [==============================] - 1s 136us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 10/10\n",
      "6314/6314 [==============================] - 1s 138us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n"
     ]
    }
   ],
   "source": [
    "def get_cnn_model_v1():   \n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "m = get_cnn_model_v1()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 50, 50)            5000      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 50, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 48, 64)            9664      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 31,561\n",
      "Trainable params: 31,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6314 samples, validate on 1579 samples\n",
      "Epoch 1/10\n",
      "6314/6314 [==============================] - 2s 314us/step - loss: -167.2800 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 2/10\n",
      "6314/6314 [==============================] - 1s 162us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 3/10\n",
      "6314/6314 [==============================] - 1s 160us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 4/10\n",
      "6314/6314 [==============================] - 1s 162us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 5/10\n",
      "6314/6314 [==============================] - 1s 163us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 6/10\n",
      "6314/6314 [==============================] - 1s 165us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 7/10\n",
      "6314/6314 [==============================] - 1s 164us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 8/10\n",
      "6314/6314 [==============================] - 1s 161us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 9/10\n",
      "6314/6314 [==============================] - 1s 183us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 10/10\n",
      "6314/6314 [==============================] - 1s 190us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_cnn_model_v2(): # added embed   \n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(100,\n",
    "                        50, #!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "m = get_cnn_model_v2()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 50, 20)            20000     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 50, 20)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 48, 256)           15616     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 101,665\n",
      "Trainable params: 101,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6314 samples, validate on 1579 samples\n",
      "Epoch 1/10\n",
      "6314/6314 [==============================] - 3s 446us/step - loss: -170.7287 - acc: 0.0705 - binary_accuracy: 0.0705 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 2/10\n",
      "6314/6314 [==============================] - 2s 287us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 3/10\n",
      "6314/6314 [==============================] - 2s 292us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 4/10\n",
      "6314/6314 [==============================] - 2s 319us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 5/10\n",
      "6314/6314 [==============================] - 2s 320us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 6/10\n",
      "6314/6314 [==============================] - 2s 339us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 7/10\n",
      "6314/6314 [==============================] - 2s 353us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 8/10\n",
      "6314/6314 [==============================] - 2s 327us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 9/10\n",
      "6314/6314 [==============================] - 2s 326us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n",
      "Epoch 10/10\n",
      "6314/6314 [==============================] - 2s 323us/step - loss: -195.0859 - acc: 0.0708 - binary_accuracy: 0.0708 - val_loss: -134.7278 - val_acc: 0.0418 - val_binary_accuracy: 0.0418\n"
     ]
    }
   ],
   "source": [
    "def get_cnn_model_v3():    # added filter\n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(256, #!!!!!!!!!!!!!!!!!!!\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "m = get_cnn_model_v3()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
