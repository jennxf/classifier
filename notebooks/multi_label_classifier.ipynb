{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,average_precision_score,confusion_matrix,cohen_kappa_score,classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/20180827_Keyword_Classification.csv\",encoding=\"utf-8\")\n",
    "df_labels=df.drop(columns=['Keyword','Unnamed: 1','Total tags'],axis=1)\n",
    "\n",
    "df['google_classes']=df_labels.apply(lambda x: x.dropna().tolist(), axis=1)\n",
    "\n",
    "df.rename(columns={'Unnamed: 1':'google_class','Keyword':'keyword'},inplace=True)\n",
    "df = df[['keyword','google_classes']]\n",
    "df.columns = ['keyword','google_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for seaborn plots only, for pandas plots, different\n",
    "def save_plot(ax,plotname):\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig('../images/{0}'.format(plotname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace \"dimension / weight\" to \"dimension_weight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.google_class = df.google_class.astype(\"str\")\n",
    "df.google_class = df.google_class.apply(lambda x: x.replace(\" / \",\"_\").replace(\" \",\"_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the google_class column to list of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now convert the labels to one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "df2 = df.join(pd.DataFrame(mlb.fit_transform(df.pop('google_class')),\n",
    "                          columns=mlb.classes_,\n",
    "                          index=df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count the number of queries by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df2.drop(['keyword'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_count.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_count[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_queries'])\n",
    "df_stats.sort_values('number_of_queries',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_intents = list(df_stats.sort_values('number_of_queries',ascending=False).head(30)['category'])\n",
    "top_intents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many queries have multi-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rowsums = df2.iloc[:,2:].sum(axis=1)\n",
    "x=rowsums.value_counts()\n",
    "#plot\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.barplot(x.index, x.values)\n",
    "plt.title(\"Multiple Categories Per Query\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('# of Categories', fontsize=12)\n",
    "save_plot(ax,'category_count.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distribution of number of words by queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = df2.keyword.str.len()\n",
    "lens.hist(bins = np.arange(0,89,1))\n",
    "fig = lens.hist(bins = np.arange(0,89,1))\n",
    "plt.title('Word Count Distribution')\n",
    "plt.ylabel('# of Queries', fontsize=12)\n",
    "plt.xlabel('# of Words', fontsize=12)\n",
    "save_plot(fig,'word_count_dist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the comments are within 50 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now clean up the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#strip all punctuations and white spaces except dollar sign and hashtags\n",
    "def clean_text(text):\n",
    "    removelist = '$#'\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    #text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub(r\"[^\\w\"+removelist+\"]\", \" \", text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['keyword2'] = df2['keyword'].map(lambda x : clean_text(x))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.drop(columns=['keyword'],inplace=True)\n",
    "\n",
    "#keyword2 column is on far right\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export final DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv('label_encoded_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df_stats.category.unique()\n",
    "train, test = train_test_split(df2, random_state=42, test_size=0.33, shuffle=True)\n",
    "\n",
    "X_train = train.keyword2\n",
    "y_train = train.drop(columns= ['keyword2'])\n",
    "X_test = test.keyword2\n",
    "y_test = test.drop(columns = ['keyword2'])\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()\n",
    "X_test.head()\n",
    "y_train.head()\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technique 1: OneVsRest multi-label strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multi-label algorithm accepts a binary mask over multiple labels. The result for each prediction will be an array of 0s and 1s marking which class labels apply to each row input sample.\n",
    "\n",
    "Naive Bayes\n",
    "OneVsRest strategy can be used for multi-label learning, where a classifier is used to predict multiple labels for instance. Naive Bayes supports multi-class, but we are in a multi-label scenario, therefore, we wrap Naive Bayes in the OneVsRestClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline combining a text feature extractor with multi lable classifier\n",
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "\n",
    "accuracy_result = []\n",
    "roc_auc_result = []\n",
    "ap_result = []\n",
    "category_list = []\n",
    "\n",
    "prediction = pd.DataFrame()\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    NB_pipeline.fit(X_train, y_train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction[category] = NB_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(y_test[category], prediction[category])))\n",
    "#     print('Test ROC_AUC is {}'.format(roc_auc_score(y_test[category], prediction)))\n",
    "    print('average_precision_score is {}'.format(average_precision_score(y_test[category], prediction[category])))\n",
    "    print('cohen_kappa_score is {}'.format(cohen_kappa_score(y_test[category], prediction[category])))\n",
    "    confusion_matrix(y_test[category], prediction[category])\n",
    "    \n",
    "    accuracy_result.append(accuracy_score(y_test[category], prediction[category]))\n",
    "#     roc_auc_result.append(average_precision_score(y_test[category], prediction))\n",
    "    ap_result.append(average_precision_score(y_test[category], prediction[category]))\n",
    "    category_list.append(category)\n",
    "    \n",
    "df_result = pd.DataFrame(\n",
    "    {'category': category_list,\n",
    "     'accuracy': accuracy_result,\n",
    "     'avg_precision_recall': ap_result\n",
    "    })\n",
    "df_result.head(10)\n",
    "print(classification_report(y_test, prediction))\n",
    "\n",
    "plt.savefig('../images/avg_pr_naive_bayes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_intents\n",
    "y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[top_intents].values\n",
    "y_test.shape\n",
    "prediction[top_intents].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2 = y_test[top_intents].values.argmax(axis=1)\n",
    "prediction2 = prediction[top_intents].values.argmax(axis=1)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test2, prediction2)\n",
    "conf_mat\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d')\n",
    "#             xticklabels = top_intents, yticklabels=top_intents)\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Model Confusion Matrix')\n",
    "# plt.savefig(\"images/conf_matrix_linearsvc.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, prediction,target_names=prediction.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2 = df_result[df_result['category'].isin(top_intents)][['avg_precision_recall','category']]\n",
    "df_result2_full = df_result[['avg_precision_recall','category']]\n",
    "\n",
    "# df_result2.plot(kind = 'barh',x = 'category',y='avg_precision_recall',figsize=(20,10),fontsize=14,legend=False)\n",
    "ax = df_result2.plot(kind = 'barh',x = 'category',y='avg_precision_recall',figsize=(20,10),fontsize=14,legend=False)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('../images/avg_pr_naive_bayes.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "            ])\n",
    "\n",
    "#Gridsearch\n",
    "parameters = {'tfidf__ngram_range': [(1, 1), (1, 2),(1,3)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'tfidf__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "              'tfidf__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "              'tfidf__stop_words': ('english', None),\n",
    "              'tfidf__smooth_idf': (True, False),\n",
    "              'tfidf__norm': ('l1', 'l2', None),\n",
    "              }\n",
    "\n",
    "grid = GridSearchCV(SVC_pipeline, parameters, cv=2, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# SVC_pipeline.fit(X_train, y_train)\n",
    "# prediction_test = SVC_pipeline_test.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipeline = joblib.load('svc_pipeline.pickle')\n",
    "svc_pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(grid.best_estimator_,'svc_pipeline.pickle',compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipeline = joblib.load('svc_pipeline.pickle')\n",
    "\n",
    "p =svc_pipeline.predict([test_query])\n",
    "print(p)\n",
    "for idx,i in enumerate(p[0]):\n",
    "    if i==1:\n",
    "        print (categories[idx])\n",
    "# prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = 'itunes reset password'\n",
    "svc_pipeline = joblib.load('svc_pipeline2.pickle')\n",
    "p =svc_pipeline.predict([test_query])\n",
    "print(p)\n",
    "for idx,i in enumerate(p[0]):\n",
    "    if i==1:\n",
    "        print (categories[idx])\n",
    "# prediction_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(prediction_test[0])\n",
    "\n",
    "for i in prediction_test[:10]:\n",
    "    print( i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dont start the below cell. it has grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SVC_pipeline = Pipeline([\n",
    " ('tfidf',\n",
    " (TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "           encoding='utf-8',\n",
    "          lowercase=True, max_df=0.25, max_features=None, min_df=1,\n",
    "          ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
    "          stop_words=None, strip_accents=None, sublinear_tf=False,\n",
    "          token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=False,\n",
    "          vocabulary=None))),\n",
    " ('clf',\n",
    "  OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
    "       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "       multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
    "       verbose=0), n_jobs=1))])\n",
    "\n",
    "SVC_pipeline.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(SVC_pipeline,'svc_pipeline2.pickle',compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC_pipeline = Pipeline([\n",
    "#                 ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "#                 ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "#             ])\n",
    "\n",
    "SVC_pipeline = Pipeline([\n",
    " ('tfidf',\n",
    " (TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "           encoding='utf-8',\n",
    "          lowercase=True, max_df=0.25, max_features=None, min_df=1,\n",
    "          ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
    "          stop_words=None, strip_accents=None, sublinear_tf=False,\n",
    "          token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=False,\n",
    "          vocabulary=None))),\n",
    " ('clf',\n",
    "  OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
    "       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "       multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
    "       verbose=0), n_jobs=1))])\n",
    "\n",
    "SVC_pipeline.fit(X_train, y_train)\n",
    "#Gridsearch\n",
    "# parameters = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "#               'tfidf__use_idf': (True, False),\n",
    "#               'tfidf__max_df': [0.25, 0.5, 0.75, 1.0],\n",
    "#               'tfidf__max_features': [10, 50, 100, 250, 500, 1000, None],\n",
    "#               'tfidf__stop_words': ('english', None),\n",
    "#               'tfidf__smooth_idf': (True, False),\n",
    "#               'tfidf__norm': ('l1', 'l2', None),\n",
    "#               }\n",
    "\n",
    "# grid = GridSearchCV(SVC_pipeline, parameters, cv=2, verbose=1)\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "prediction = pd.DataFrame()\n",
    "accuracy_result = []\n",
    "roc_auc_result = []\n",
    "ap_result = []\n",
    "category_list = []\n",
    "\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    SVC_pipeline.fit(X_train, y_train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction[category] = SVC_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(y_test[category], prediction[category])))\n",
    "    accuracy_result.append(accuracy_score(y_test[category], prediction[category]))\n",
    "    ap_result.append(average_precision_score(y_test[category], prediction[category]))\n",
    "    category_list.append(category)\n",
    "    \n",
    "df_result_svc = pd.DataFrame(\n",
    "    {'category': category_list,\n",
    "     'accuracy_svc': accuracy_result,\n",
    "     'avg_precision_recall_svc': ap_result\n",
    "    })\n",
    "df_result_svc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(SVC_pipeline,'svc_pipeline2.pickle',compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result_svc[['category','avg_precision_recall_svc']].dropna().to_csv('../data/avg_precision_recall_stats.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_svc[['category','avg_precision_recall_svc']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_svc2 = df_result_svc[df_result_svc['category'].isin(top_intents)][['avg_precision_recall_svc','category']]\n",
    "df_result_svc2.plot(kind = 'barh',x = 'category',y='avg_precision_recall_svc',figsize=(20,10),fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing SVC with real data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_pipeline = joblib.load('svc_pipeline2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# svc_pipeline\n",
    "def return_class(test_query):\n",
    "    list_of_predicted_intents = []\n",
    "    for category in categories:\n",
    "        SVC_pipeline.fit(X_train, train[category])\n",
    "        predicted = SVC_pipeline.predict([test_query])\n",
    "    #     print (predicted)\n",
    "        if predicted[0] ==1:\n",
    "            list_of_predicted_intents.append(category)\n",
    "    return list_of_predicted_intents\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_query = 'itunes password reset'\n",
    "for i in l:\n",
    "    print( i)\n",
    "    return_class(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l =list(X_test)\n",
    "test_query = 'itunes password reset'\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)),\n",
    "            ])\n",
    "# for category in categories:\n",
    "for category in ['nan','iTunes','iPod']:\n",
    "#      print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = LogReg_pipeline.predict([test_query])\n",
    "    print (category)\n",
    "    print(prediction) # for each category, the classifier will either print 1 or 0 to tell you that this query belongs to any of the class. \n",
    "#     print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "    idx_list = []\n",
    "    for idx,i in enumerate(prediction):\n",
    "        if i ==1:\n",
    "            idx_list.append(idx)\n",
    "\n",
    "    for i in idx_list:\n",
    "        print(l[i])\n",
    "        print (len(y_test[category]))\n",
    "        print (len((prediction)))\n",
    "#     print (test[category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)),\n",
    "            ])\n",
    "\n",
    "accuracy_result = []\n",
    "ap_result = []\n",
    "category_list = []\n",
    "\n",
    "prediction = pd.DataFrame()\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline.fit(X_train, y_train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction[category] = LogReg_pipeline.predict(X_test)\n",
    "    accuracy_result.append(accuracy_score(y_test[category], prediction[category]))\n",
    "    ap_result.append(average_precision_score(y_test[category], prediction))\n",
    "    category_list.append(category)\n",
    "    \n",
    "df_result_lg = pd.DataFrame(\n",
    "    {'category': category_list,\n",
    "     'accuracy_lg': accuracy_result,\n",
    "     'avg_precision_recall_lg': ap_result\n",
    "    })\n",
    "df_result_lg.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_lg2 = df_result_lg[df_result_lg['category'].isin(top_intents)][['avg_precision_recall_lg','category']]\n",
    "df_result_lg2.plot(kind = 'barh',x = 'category',y='avg_precision_recall_lg',figsize=(20,10),fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge 3 charts to visualize side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_chart = pd.merge(df_result2,df_result_svc2, on='category')\n",
    "df_chart2 = pd.merge(df_chart,df_result_lg2,on='category')\n",
    "df_chart2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_chart2.to_csv(\"../data/avg_precision_recall_stats.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_chart2.plot(kind='barh',x='category',figsize=(50,50),fontsize=40)\n",
    "ax = df_chart2.plot(kind='barh',x='category',figsize=(50,50),fontsize=40)\n",
    "fig = ax.get_figure()\n",
    "plt.title(\"Comparison or Avg PR score for each model\",fontsize=50)\n",
    "plt.legend(fontsize=40) # using a size in points\n",
    "fig.savefig('../images/comparison_pr_result.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chart2.category.unique()\n",
    "df_chart2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Seaborn to plot comparison PR chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt = pd.melt(df_chart2, id_vars=\"category\", var_name=\"model\", value_name=\"avg_pr_score\")\n",
    "\n",
    "df_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "fig, ax = pyplot.subplots(figsize=(30,20))\n",
    "\n",
    "current_palette = sns.color_palette(\"bright\")\n",
    "sns.set_palette(current_palette)\n",
    "sns.set(font_scale=1)\n",
    "sns.catplot(y='category', x='avg_pr_score', hue='model', data=df_melt, kind='bar',ax=ax,legend=False)\n",
    "ax.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(categories)\n",
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../data/20180827_Keyword_Classification.csv\")\n",
    "df_raw.head()\n",
    "# df_raw.google_class = df_raw.google_class.astype(str)\n",
    "\n",
    "# reset_test = test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/20180827_Keyword_Classification.csv\",encoding=\"utf-8\")\n",
    "df_labels=df_test.drop(columns=['Keyword','Unnamed: 1','Total tags'],axis=1)\n",
    "\n",
    "df_test['google_classes']=df_labels.apply(lambda x: x.dropna().tolist(), axis=1)\n",
    "\n",
    "df_test.rename(columns={'Unnamed: 1':'google_class','Keyword':'keyword'},inplace=True)\n",
    "# df = df[['keyword','google_classes']]\n",
    "# df.columns = ['keyword','google_class']\n",
    "\n",
    "df_test = df_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.rename(columns={'index':'idx'},inplace=True)\n",
    "test_queries = df_test.keyword.tolist()[:10]\n",
    "test_indexes = df_test.idx.tolist()[:10]\n",
    "t = list(zip(test_queries,test_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_columns = pd.DataFrame(y_test.columns.tolist(),columns=['tag_name'])\n",
    "y_test_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.keyword.sample(n=100).to_csv(\"../data/test_input_file.csv\",index=False)\n",
    "y_test_columns.to_csv('../data/tag_list.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipeline = joblib.load('svc_pipeline2.pickle')\n",
    "\n",
    "\n",
    "for tup in t:\n",
    "    print (\"query : {0}\".format(tup[0]))\n",
    "    predicted = svc_pipeline.predict([tup[0]])\n",
    "    print(predicted)\n",
    "#     predicted\n",
    "#     print (predicted)\n",
    "\n",
    "#     predicted contains list of probabilities for each of the 140 class. You will set your own threshold.\n",
    "#     Example: If > some_threshold then 1 else 0.\n",
    "    \n",
    "    predicted_list = []\n",
    "    selected_categories = y_test.columns\n",
    "    for i, p in enumerate(predicted[0]):\n",
    "        if p==1:\n",
    "            predicted_list.append(selected_categories[i])\n",
    "    print( \"predicted tags : {0}\".format(predicted_list))\n",
    "#     print(\"true tags : {0}\".format(df_test.google_classes.iloc[tup[1]].split(\",\")))\n",
    "    print(\"true tags : {0}\".format(df_test.google_classes.iloc[tup[1]]))\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    for i in predicted_list:\n",
    "#         if i in df_test.google_classes.ix[tup[1]].split(\",\")\n",
    "        if i in df_test.google_classes.ix[tup[1]]:\n",
    "            count +=1\n",
    "#     percent = round(count/len(df_test.google_classes.iloc[tup[1]].split(\",\")),2)*100\n",
    "    percent = round(count/len(df_test.google_classes.iloc[tup[1]]),2)*100\n",
    "\n",
    "    print(\"percentage of predicted in true tags: {0} %\".format(str(percent)))\n",
    "    print()\n",
    "    print(\"****************************************\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
